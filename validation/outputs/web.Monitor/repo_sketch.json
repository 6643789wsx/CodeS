[
    {
        "readme": "# web.Monitor\n\nFast & user-friendly web change tracking tool.\n\n## Why?\n\n**Continuous Monitoring:** The script can automatically check web pages at regular intervals to detect any changes.\n\n**Flexible Setup:** You can add individual URLs or load a list of URLs from a file.\n\n**Persistent Storage:** It uses sqlite module to store the web data in a database file, allowing persistence across runs.\n\n**Detailed Logging:** It doesn't just check if the page is up, but also logs the HTTP code, content length, and the page title.\n\n**Notifications:** Upon detecting a change, the script not only prints it on the console but can also send out a notification.\n\n**Change Visualization:** Provides functionality to view all recorded changes for a specific domain or URL, aiding in historical tracking.\n\n**Domain Filtering:** If you're only interested in checking URLs of a specific domain, the script allows you to filter and only check those domains.\n\n**Automation:** With the hour-based repetition option, the script can operate in a loop, checking web pages every set number of hours.\n\n**Customization and Extension:** Being an open-source script, you can tailor it to your needs or add more functionalities.\n\n## Features\n- **Fast**\n- **Easy to use**\n- **Easy to install**\n- **Continuously save new changes in the local database (with the possibility of dumping them all)**\n- **Telegram/slack/discord notifications**\n\n## Help Menu\n**web.Monitor** flags:\n\n````console\noptions:\n  -h, --help            show this help message and exit\n  --add ADD             Add a URL to monitor.\n  --add-urls ADD_URLS   Add URLs from a file to monitor.\n  --check               Check all the websites for changes.\n  -D DOMAIN, --domain DOMAIN\n                        Check websites for a specific root domain.\n  -df DOMAIN_FILE, --domain-file DOMAIN_FILE\n                        Check websites for root domains specified in a file.\n  --show-changes        Show changes for the specified domain or URL.\n  -H HOURS, --hours HOURS\n                        Repeat the website check every X hours.\n  -url URL, --url URL   Show changes for a specific URL.\n````\n\n## Previous needed configurations\n\n  You need to write the configuration (api) path files into **config.ini** file.\n  \n- [Httpx](https://github.com/projectdiscovery/httpx) binary.\n- [Notify](https://github.com/owasp-amass/amass/blob/master/examples/config.ini) binary.\n- Notify api configuration file.\n\n## Work plan\n\n``IMPORTANT``: I had to change from shelve library to sqlite3 because I had some problems with my VPS. It was generating different database files (I don't really know why, on my local machine was working correctly).\n\nFirst of all, is needed to add a URL (or URLs) to the database:\n\n````console\npython3 web.monitor.py --add-urls urls.txt\npython3 web.monitor.py --add http://example.com:81\n````\n\nNow, you can start scanning. It's important to note that the first result will be saved on the database but you won't receive a notification, the script will start sending notifications after the first scan.\n\nOnce all the URLs are on the database, you can start scanning with the following command:\n\n````console\npython3 web.monitor.py -df roots.txt --check -H 1\npython3 web.monitor.py -D example.com --check -H 1\n````\n\nThe ``-df`` flag is used to scan all URLs from a root domain, for example, if the URL ``admin.example.com`` and ``admin.example2.com`` are on the database and the ``roots.txt`` file has only ``*.example.com`` will be scanned. The ``-D`` flag scans only ``*.example.com`` URLs. The ``-H`` flag is used to specify the domain that each 1 hour will be performed a scan, of course, you can customize that, in any case, I recommend scanning each 12 or 24 hours.\n\nIf you want to dump all URLs from a given domain you can use:\n\n````console\n\u279c  python3 web.monitor.py -D example.com --show-changes\n\n               _     __  __             _ _\n              | |   |  \\/  |           (_) |\n __      _____| |__ | \\  / | ___  _ __  _| |_ ___  _ __\n \\ \\ /\\ / / _ \\ '_ \\| |\\/| |/ _ \\| '_ \\| | __/ _ \\| '__|\n  \\ V  V /  __/ |_) | |  | | (_) | | | | | || (_) | |\n   \\_/\\_/ \\___|_.__/|_|  |_|\\___/|_| |_|_|\\__\\___/|_|\n\n                        github.com/e1abrador/web.Monitor\n\nexample.com:81/\n[2023-09-10 00:58:16.694612] http://example.com:81/ [200] [3463] [Test 1]\n[2023-09-10 00:58:25.382700] http://example.com:81/ [200] [39386] [Test 1]\n\nexample.com:82/\n[2023-09-10 00:56:42.354195] http://example.com:82/ [200] [3463] [Test 2]\n[2023-09-10 00:57:27.545999] http://example.com:82/ [200] [39386] [Test 2]\n[2023-09-10 00:57:38.478968] http://example.com:82/ [200] [2666] [Test 2]\n````\n\nYou can check 1 single URL with ``--url`` flag too:\n\n````console\npython3 web.monitor.py --url http://example.com:81 --show-changes\n\n               _     __  __             _ _\n              | |   |  \\/  |           (_) |\n __      _____| |__ | \\  / | ___  _ __  _| |_ ___  _ __\n \\ \\ /\\ / / _ \\ '_ \\| |\\/| |/ _ \\| '_ \\| | __/ _ \\| '__|\n  \\ V  V /  __/ |_) | |  | | (_) | | | | | || (_) | |\n   \\_/\\_/ \\___|_.__/|_|  |_|\\___/|_| |_|_|\\__\\___/|_|\n\n                        github.com/e1abrador/web.Monitor\n\n[2023-09-10 21:51:46.626917] http://example.com:81 [200] [21535] [Test 1]\n[2023-09-10 21:51:53.748105] http://example.com:81 [200] [2666] [Test 2]\n[2023-09-10 21:58:25.827493] http://example.com:81 [200] [35127] [Test 3]\n````\n\n\n\nNote that when using the above command, every URL that contains the domain used in ``-D`` flag will be used, in this example the script will show *.example.com.",
        "instruction": "Below is a detailed README.md of repository. Please write a repository sketch in the form of a tree, including all folders, files, as well as imports information if necessary.\n\n---\nREADME.md\n---\n# web.Monitor\n\nFast & user-friendly web change tracking tool.\n\n## Why?\n\n**Continuous Monitoring:** The script can automatically check web pages at regular intervals to detect any changes.\n\n**Flexible Setup:** You can add individual URLs or load a list of URLs from a file.\n\n**Persistent Storage:** It uses sqlite module to store the web data in a database file, allowing persistence across runs.\n\n**Detailed Logging:** It doesn't just check if the page is up, but also logs the HTTP code, content length, and the page title.\n\n**Notifications:** Upon detecting a change, the script not only prints it on the console but can also send out a notification.\n\n**Change Visualization:** Provides functionality to view all recorded changes for a specific domain or URL, aiding in historical tracking.\n\n**Domain Filtering:** If you're only interested in checking URLs of a specific domain, the script allows you to filter and only check those domains.\n\n**Automation:** With the hour-based repetition option, the script can operate in a loop, checking web pages every set number of hours.\n\n**Customization and Extension:** Being an open-source script, you can tailor it to your needs or add more functionalities.\n\n## Features\n- **Fast**\n- **Easy to use**\n- **Easy to install**\n- **Continuously save new changes in the local database (with the possibility of dumping them all)**\n- **Telegram/slack/discord notifications**\n\n## Help Menu\n**web.Monitor** flags:\n\n````console\noptions:\n  -h, --help            show this help message and exit\n  --add ADD             Add a URL to monitor.\n  --add-urls ADD_URLS   Add URLs from a file to monitor.\n  --check               Check all the websites for changes.\n  -D DOMAIN, --domain DOMAIN\n                        Check websites for a specific root domain.\n  -df DOMAIN_FILE, --domain-file DOMAIN_FILE\n                        Check websites for root domains specified in a file.\n  --show-changes        Show changes for the specified domain or URL.\n  -H HOURS, --hours HOURS\n                        Repeat the website check every X hours.\n  -url URL, --url URL   Show changes for a specific URL.\n````\n\n## Previous needed configurations\n\n  You need to write the configuration (api) path files into **config.ini** file.\n  \n- [Httpx](https://github.com/projectdiscovery/httpx) binary.\n- [Notify](https://github.com/owasp-amass/amass/blob/master/examples/config.ini) binary.\n- Notify api configuration file.\n\n## Work plan\n\n``IMPORTANT``: I had to change from shelve library to sqlite3 because I had some problems with my VPS. It was generating different database files (I don't really know why, on my local machine was working correctly).\n\nFirst of all, is needed to add a URL (or URLs) to the database:\n\n````console\npython3 web.monitor.py --add-urls urls.txt\npython3 web.monitor.py --add http://example.com:81\n````\n\nNow, you can start scanning. It's important to note that the first result will be saved on the database but you won't receive a notification, the script will start sending notifications after the first scan.\n\nOnce all the URLs are on the database, you can start scanning with the following command:\n\n````console\npython3 web.monitor.py -df roots.txt --check -H 1\npython3 web.monitor.py -D example.com --check -H 1\n````\n\nThe ``-df`` flag is used to scan all URLs from a root domain, for example, if the URL ``admin.example.com`` and ``admin.example2.com`` are on the database and the ``roots.txt`` file has only ``*.example.com`` will be scanned. The ``-D`` flag scans only ``*.example.com`` URLs. The ``-H`` flag is used to specify the domain that each 1 hour will be performed a scan, of course, you can customize that, in any case, I recommend scanning each 12 or 24 hours.\n\nIf you want to dump all URLs from a given domain you can use:\n\n````console\n\u279c  python3 web.monitor.py -D example.com --show-changes\n\n               _     __  __             _ _\n              | |   |  \\/  |           (_) |\n __      _____| |__ | \\  / | ___  _ __  _| |_ ___  _ __\n \\ \\ /\\ / / _ \\ '_ \\| |\\/| |/ _ \\| '_ \\| | __/ _ \\| '__|\n  \\ V  V /  __/ |_) | |  | | (_) | | | | | || (_) | |\n   \\_/\\_/ \\___|_.__/|_|  |_|\\___/|_| |_|_|\\__\\___/|_|\n\n                        github.com/e1abrador/web.Monitor\n\nexample.com:81/\n[2023-09-10 00:58:16.694612] http://example.com:81/ [200] [3463] [Test 1]\n[2023-09-10 00:58:25.382700] http://example.com:81/ [200] [39386] [Test 1]\n\nexample.com:82/\n[2023-09-10 00:56:42.354195] http://example.com:82/ [200] [3463] [Test 2]\n[2023-09-10 00:57:27.545999] http://example.com:82/ [200] [39386] [Test 2]\n[2023-09-10 00:57:38.478968] http://example.com:82/ [200] [2666] [Test 2]\n````\n\nYou can check 1 single URL with ``--url`` flag too:\n\n````console\npython3 web.monitor.py --url http://example.com:81 --show-changes\n\n               _     __  __             _ _\n              | |   |  \\/  |           (_) |\n __      _____| |__ | \\  / | ___  _ __  _| |_ ___  _ __\n \\ \\ /\\ / / _ \\ '_ \\| |\\/| |/ _ \\| '_ \\| | __/ _ \\| '__|\n  \\ V  V /  __/ |_) | |  | | (_) | | | | | || (_) | |\n   \\_/\\_/ \\___|_.__/|_|  |_|\\___/|_| |_|_|\\__\\___/|_|\n\n                        github.com/e1abrador/web.Monitor\n\n[2023-09-10 21:51:46.626917] http://example.com:81 [200] [21535] [Test 1]\n[2023-09-10 21:51:53.748105] http://example.com:81 [200] [2666] [Test 2]\n[2023-09-10 21:58:25.827493] http://example.com:81 [200] [35127] [Test 3]\n````\n\n\n\nNote that when using the above command, every URL that contains the domain used in ``-D`` flag will be used, in this example the script will show *.example.com.\n\n---\nRepository Sketch\n---\n",
        "input": "",
        "output": "Here is a practicable repository sketch.\n\n```\n.\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 web.monitor.py\n```"
    }
]